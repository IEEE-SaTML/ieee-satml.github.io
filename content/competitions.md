title: Competitions
menu_title: Competitions
template: page
menu_order: 300

## Competition Track

SaTML traditionally includes a *Competition Track* as part of its program. Participants are invited to engage in selected data science competitions, competing to achieve the highest score on relevant machine learning or security tasks. These tasks are based on well-defined problems and corresponding datasets provided by the competition organizers. The competition results will be presented and discussed during dedicated sessions at the conference (see [Call for Competitions](/call-for-competitions) for details). 

## Accepted Competitions

For this year, the following competitions have been accepted for the conference. Interested researchers can participate in any of these by following the instructions provided on the competition websites. For more information or specific inquiries, please contact the respective competition organizers directly.

<a class="anchor" name="competition1"></a>
### üèÅ Detecting Manipulations of AI Models in Space Operations

Website: <https://assurance-ai.space-codev.org/competitions/>

> The competition is a part of the "Assurance for Space Domain AI Applications" project funded by the European Space Agency. It looks for effective algorithms to identify security issues in AI models across two real-life space operation scenarios: 1) manipulated outputs from LLM-based summarization of space-related texts ("Impostor Hunt") and 2) hidden triggers in models for spacecraft telemetry forecasting ("Trojan Horse Hunt").

Organizers: Agata Kaczmarek, Dawid P≈Çudowski, Piotr Wilczy≈Ñski, Przemys≈Çaw Biecek, Artur Janicki, Krzysztof Kotowski, Ramez Shendy, Jakub Nalepa, and Evridiki Ntagiou.

<a class="anchor" name="competition2"></a>
### üèÅ Anti-BAD: An Anti-Backdoor Challenge for Post-Trained Large Language Models

Website: <https://anti-bad.github.io/>

> This competition invites participants to defend against backdoors in large language models under practical deployment constraints (i.e., without access to training data or poisoned prior knowledge). Spanning generation, classification, and multilingual tracks, Anti-BAD encourages lightweight yet effective defenses that restore model integrity while preserving utility in practical post-trained scenarios common to model-sharing ecosystems.

Organizers: Weijun Li, Jinrui Yang, Ansh Arora, Yiyi Chen, Xuanli He, Heather Lent, Johannes Bjerva, Mark Dras, and Qiongkai Xu.

<!-- <a class="anchor" name="competition3"></a>
##### üèÅ Membership Inference on Diffusion-model-based Synthetic Tabular Data

Website: <https://vectorinstitute.github.io/MIDST>

> The MIDST challenge invites participants to assess the privacy risks of synthetic tabular data generated by diffusion models using membership inference attacks. Participants will be able to develop and apply strategies in both blackbox and whitebox settings to determine if specific data points were included in training during the synthesis of single or multi-relational tables.

Organizers: Masoumeh Shafieinejad, Xi He, John Jewell, Mahshid Alinoori, Sana Ayromlou, Wei Pang, Gauri Sharma, Veronica Chatrath, and Deval Pandya.

<a class="anchor" name="competition4"></a>
##### üèÅ Robust Android Malware Detection Competition

Website: <https://ramd-competition.github.io>

> The Robust Android Malware Detection Competition aims to evaluate machine learning-based detectors with respect to (i) temporal data drift due to the evolution of both malware and legitimate applications and (ii) adversarial manipulations of malware samples to evade detection. The competition consists of three separate tracks (i.e., Adversarial Robustness to Feature-space Attacks, Adversarial Robustness to Problem-space Attacks, and Temporal Robustness to Data Drift).

Organizers: Angelo Sotgiu, Maura Pintor, Ambra Demontis, and Battista Biggio. -->